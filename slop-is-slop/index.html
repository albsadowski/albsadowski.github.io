<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="albert's blog"><link rel="shortcut icon" href=https://albsadowski.github.io/favicon.ico><link rel=stylesheet href=/css/style.min.css><link rel=canonical href=https://albsadowski.github.io/slop-is-slop/><title>Slop Is Slop</title></head><body><header id=banner><h2><a href=https://albsadowski.github.io/>albert's blog</a></h2><nav><ul><li><a href=/ title=posts>posts</a></li><li><a href=/research/ title=research>research</a></li><li><a href=/about/ title=about>about</a></li></ul></nav></header><main id=content><article><header id=post-header><h1>Slop Is Slop</h1><div><time>November 1, 2025</time></div></header><p>The discourse around AI has recently unlocked a new fear: the potential for apps like Meta&rsquo;s Vibes and OpenAI&rsquo;s Sora to flood the internet with <em>AI-generated slop</em>. This anxiety mirrors the concerns that emerged after ChatGPT&rsquo;s popularization, centered on a future saturated with low-quality, AI-generated content.</p><p>It&rsquo;s important to draw a line here. When I talk about <em>slop</em>, I mean low-quality, high-volume filler content. I am not talking about deliberate, malicious disinformation. Automated fake news is a separate and serious problem, but it&rsquo;s not this one.</p><p>My observation is about the quality of our media environment. And on that front, I&rsquo;m struggling to see the new problem. My core point is this: I often can&rsquo;t tell the difference between AI-generated slop and human-generated slop. Slop is slop.</p><p>Think about the internet before the current AI boom. When I navigate many <em>internet portals</em>, the content is already optimized for algorithms, not for readers. Clickbait headlines, thin articles, and content made to sell a product are the norm. This ecosystem of human-generated slop, designed to please algorithms and make a profit, was already here.</p><p>The same applies to short-form video. TikTok and Instagram Reels are already saturated with content that could be called <em>brain rot</em>. This is, to date, overwhelmingly human-generated. The fear is that AI will make more of this, but it’s not clear if this is a new kind of problem or just&mldr; more of the same.</p><p>There is, however, a valid concern. AI, with its potential for hyper-personalization, could create content loops even more addictive than what human-driven algorithms currently produce. This is a risk worth monitoring.</p><p>This isn&rsquo;t new to the internet, either. I recall broadcast television from a decade ago. <em>Swapping channels</em> through hours of low-quality programming is conceptually similar to scrolling an endless feed. While today&rsquo;s platforms are arguably more potent and better at <em>attention theft</em>, the core behavior of passive, low-engagement consumption is not new.</p><p>This leads me to question the precise nature of the fear. Is the concern that corporations have now learned to automate slop? If so, the primary threat here isn&rsquo;t to the audience, who are already consuming slop, but to the human creators who were previously paid to make it.</p><p>Perhaps the real problem isn&rsquo;t the AI at all. The real problem is that we&rsquo;ve built an internet that rewards slop, no matter who or what creates it. The AI isn&rsquo;t the cause; it&rsquo;s just the most efficient tool we&rsquo;ve found for feeding the system we already built.</p></article></main><footer id=footer>Copyright © 2025 Albert Sadowski</footer></body></html>